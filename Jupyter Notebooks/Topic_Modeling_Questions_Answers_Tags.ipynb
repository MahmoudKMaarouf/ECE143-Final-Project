{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QAT_list=QAT_list.values.tolist() # Insert QAT_list into list\n",
    "QAT_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns # Import seaborn for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk # Import natural language toolkit library\n",
    "nltk.download('stopwords')\n",
    "import pyLDAvis #Import pyLDAvis for interactive visualization\n",
    "import pyLDAvis.gensim\n",
    "import gensim #Import gensim for topic modelling \n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "try:\n",
    "    import spacy #Import Spacy for lemmatization\n",
    "    from scipy.sparse.sparsetools.csr import _csr\n",
    "\n",
    "except:\n",
    "    from scipy.sparse import sparsetools as _csr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bigram and trigram sequences\n",
    "bigram = gensim.models.Phrases(QAT_list, min_count=20, threshold=100) \n",
    "trigram = gensim.models.Phrases(bigram[QAT_list], threshold=100)\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm  #English pipeline optimized for CPU. Components: tok2vec, tagger, parser, senter, ner, attribute_ruler, lemmatizer.\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tagger\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "# get stopwords from nltk fro preprocessing\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def process_words(texts, stop_words=stop_words, allowed_tags=['NOUN', 'VERB']):\n",
    "    \n",
    "    \"\"\"\n",
    "    Transform the  questions into lowercase, build bigrams-trigrams, and apply lemmatization\n",
    "\n",
    "    \"\"\"\n",
    "    # remove stopwords, short tokens and letter accents \n",
    "    texts = [[word for word in simple_preprocess(str(doc), deacc=True, min_len=3) if word not in stop_words] for doc in texts]\n",
    "    \n",
    "    # bi-gram and tri-gram implementation\n",
    "    texts = [bigram_mod[doc] for doc in texts]\n",
    "    texts = [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "    \n",
    "    texts_out = []\n",
    "    \n",
    "    # implement lemmatization and filter out unwanted part of speech tags\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_tags])\n",
    "    \n",
    "    # remove stopwords and short tokens again after lemmatization\n",
    "    texts_out = [[word for word in simple_preprocess(str(doc), deacc=True, min_len=3) if word not in stop_words] for doc in texts_out]    \n",
    "    \n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = process_words(QAT_list) #Apply processing functions to the list\n",
    "processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = corpora.Dictionary(processed_data) # Create dictionary of the words \n",
    "print('Vocabulary Size:', len(id2word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [id2word.doc2bow(text) for text in processed_data] #Create Corpus tuple (BoW format) containing the each word id and their frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dictionary and dataframe of Corpus to remove the high frequncy words \n",
    "dict_corpus = {}\n",
    "\n",
    "for i in range(len(corpus)):\n",
    "  for idx, freq in corpus[i]:\n",
    "    if id2word[idx] in dict_corpus:\n",
    "      dict_corpus[id2word[idx]] += freq\n",
    "    else:\n",
    "       dict_corpus[id2word[idx]] = freq\n",
    "       \n",
    "dict_df = pd.DataFrame.from_dict(dict_corpus, orient='index', columns=['freq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot histogram of word frequency \n",
    "plt.figure(figsize=(8,6))\n",
    "sns.histplot(dict_df['freq'], bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Top 25 high-frequency words\n",
    "dict_df2=dict_df.sort_values('freq', ascending=False).head(25) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out high-frequancy words based on the pre-defined threshold\n",
    "extension = dict_df[dict_df.freq>598438].index.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of other non-relevant words identified by inspection that need to be filterd out\n",
    "unrelevant=['problem','reason','luck','book','purpose','nose','clue','happen','scucceed','reason','thought','oppose','hope','realize','cheer','want','example','laptop','guy','look','need','write', 'walk','good', 'lot', 'people', 'great','please','wikipedia','fun','movie', 'problem', 'answer','thank','need', 'question', 'thing','suggest','solution', 'wrong', 'prefer', 'mention', 'correctly', 'good', 'easy', 'follow', 'great', 'feel', 'idea', 'recommend', 'support','want','look','way','pretty', 'result', 'basic', 'give', 'bad', 'nice', 'try', 'well', 'write', 'look']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add non-relevant words to high-frequncy words\n",
    "extension.extend(unrelevant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add high-frequency and nor-relevant words to stop words list\n",
    "stop_words.extend(extension)\n",
    "# Rerun the word processing function\n",
    "processed_data= process_words(QAT_list)\n",
    "# Recreate Dictionary\n",
    "id2word = corpora.Dictionary(processed_data)\n",
    "print('New Vocabulary Size:', len(id2word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out words that occur on less than 10 questions, or on more than 60% of the questions.\n",
    "id2word.filter_extremes(no_below=10, no_above=0.6)\n",
    "print('Total Vocabulary Size:', len(id2word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the corpus \n",
    "corpus = [id2word.doc2bow(text) for text in processed_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(corpus, open(\"corpus_100_QAT.pkl\", \"wb\")) #Pickle the corpus and id2word to restart the kernel with fresh memory\n",
    "pickle.dump(id2word, open(\"id2word_100_QAT.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from gensim.models.wrappers import LdaMallet  # Import Mallet LDA\n",
    "num_topics=100 # Number of Topics\n",
    "\n",
    "# Path to Mallet Change to correct path\n",
    "os.environ['MALLET_HOME'] = '\\\\Users\\\\hamed\\\\mallet-2.0.8' \n",
    "mallet_path = '\\\\Users\\\\hamed\\\\mallet-2.0.8\\\\bin\\\\mallet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Built the topic model using Mallet LDA implementation\n",
    "ldamallet =gensim.models.wrappers.LdaMallet(mallet_path=mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the topics compiled by the model and diplay 5 term and their relative weights\n",
    "from pprint import pprint\n",
    "pprint(ldamallet.show_topics(num_words=5,formatted=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Coherence Score\n",
    "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=processed_data, dictionary=id2word, coherence='c_v')\n",
    "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "print('Coherence Score: ', coherence_ldamallet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "corpus = pickle.load(open(\"corpus_100_QAT.pkl\", \"rb\"))\n",
    "id2word = pickle.load(open(\"id2word_100_QAT.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build another model using multicore LDA implementation and compare the coherence score\n",
    "from gensim.models import LdaMulticore\n",
    "ldamulticore = LdaMulticore(corpus=corpus, num_topics=num_topics, id2word=id2word,workers=4, eval_every=None, passes=20, batch=True,per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display topics\n",
    "from pprint import pprint\n",
    "pprint(ldamulticore.show_topics(num_words=5,formatted=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Coherence Score for the multicore model\n",
    "processed_data = pickle.load(open(\"processed_data_100_QAT.pkl\", \"rb\"))\n",
    "coherence_model_ldamulticore = CoherenceModel(model=ldamulticore, texts=processed_data, dictionary=id2word, coherence='c_v')\n",
    "coherence_ldamulticore = coherence_model_ldamulticore.get_coherence()\n",
    "print('Coherence Score: ', coherence_ldamulticore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build another model using LDA implementation and compare the coherence score with the two previous models\n",
    "from gensim.models import LdaModel\n",
    "ldamodel = LdaModel(corpus=corpus, num_topics=num_topics, id2word=id2word, eval_every=None, passes=20,per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display topics\n",
    "pprint(ldamodel.show_topics(num_words=5,formatted=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Coherence Score\n",
    "coherence_model_ldamodel = CoherenceModel(model=ldamodel, texts=processed_data, dictionary=id2word, coherence='c_v')\n",
    "coherence_ldamodel = coherence_model_ldamodel.get_coherence()\n",
    "print('Coherence Score: ', coherence_ldamodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_difference_plotly(mdiff, title=\"\", annotation=None):\n",
    "    \"\"\"Plot the difference between models using plotly. The chart will be interactive\"\"\"\n",
    "    import plotly.graph_objs as go\n",
    "    import plotly.offline as py\n",
    "\n",
    "    annotation_html = None\n",
    "    if annotation is not None:\n",
    "        annotation_html = [\n",
    "            [\n",
    "                \"+++ {}<br>--- {}\".format(\", \".join(int_tokens), \", \".join(diff_tokens))\n",
    "                for (int_tokens, diff_tokens) in row\n",
    "            ]\n",
    "            for row in annotation\n",
    "        ]\n",
    "\n",
    "    data = go.Heatmap(z=mdiff, colorscale='RdBu', text=annotation_html)\n",
    "    layout = go.Layout(width=950, height=950, title=title, xaxis=dict(title=\"topic\"), yaxis=dict(title=\"topic\"))\n",
    "    py.iplot(dict(data=[data], layout=layout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_difference_matplotlib(mdiff, title=\"\", annotation=None):\n",
    "    \"\"\" function to plot difference between modelsUses using matplotlib\"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig, ax = plt.subplots(figsize=(18, 14))\n",
    "    data = ax.imshow(mdiff, cmap='RdBu_r', origin='lower')\n",
    "    plt.title(title)\n",
    "    plt.colorbar(data)\n",
    "try:\n",
    "    get_ipython()\n",
    "    import plotly.offline as py\n",
    "except Exception:\n",
    "\n",
    "    plot_difference = plot_difference_matplotlib\n",
    "    \n",
    "else:\n",
    "    py.init_notebook_mode()\n",
    "    plot_difference = plot_difference_plotly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap to compare the correlation between LDA and Multicore LDA\n",
    "mdiff, annotation = ldamodel.diff(ldamulticore, distance='jaccard', num_words=30)\n",
    "plot_difference(mdiff, title=\"LDA vs LDA Multicore Topic difference by Jaccard distance\", annotation=annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert LdaMallet model to a gensim model for Visualization\n",
    "\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "def convertldaMalletToldaGen(mallet_model):\n",
    "    model_gensim = LdaModel(\n",
    "        id2word=mallet_model.id2word, num_topics=mallet_model.num_topics,\n",
    "        alpha=mallet_model.alpha) \n",
    "    model_gensim.state.sstats[...] = mallet_model.wordtopics\n",
    "    model_gensim.sync_state()\n",
    "    return model_gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldagensim = convertldaMalletToldaGen(ldamallet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap to compare the correlation between LDA and Multicore LDA\n",
    "mdiff, annotation = ldagensim.diff(ldamulticore, distance='jaccard', num_words=30)\n",
    "plot_difference(mdiff, title=\"LDA Mallet vs LDA Multicore Topic difference by Jaccard distance\", annotation=annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the topic distributions by passing in the corpus to the model\n",
    "tm_results = ldamallet[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the most dominant topic\n",
    "corpus_topics = [sorted(topics, key=lambda record: -record[1])[0] for topics in tm_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top  significant terms and their probabilities for each topic using ldamallet\n",
    "topics = [[(term, round(wt, 3)) for term, wt in ldamallet.show_topic(n, topn=20)] for n in range(0, ldamallet.num_topics)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top  significant terms and their probabilities for each topic using LDA multicore\n",
    "topics_ldamulticore = [[(term, round(wt, 3)) for term, wt in ldamulticore.show_topic(n, topn=20)] for n in range(0, ldamulticore.num_topics)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from gensim.models import CoherenceModel\n",
    "ldamodel = pickle.load(open(\"\\\\Users\\\\hamed\\\\Desktop\\\\ECE 143 Project Data Files\\\\ldamodel_100_QAT.pkl\", \"rb\"))\n",
    "ldamulticore = pickle.load(open(\"\\\\Users\\\\hamed\\\\Desktop\\\\ECE 143 Project Data Files\\\\ldamulticore_100_QAT.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top  significant terms and their probabilities for each topic using LDA multicore\n",
    "topics_ldam = [[(term, round(wt, 3)) for term, wt in ldamodel.show_topic(n, topn=20)] for n in range(0, ldamodel.num_topics)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 most probable words for each topic for LDA \n",
    "topics_df = pd.DataFrame([[term for term, wt in topic] for topic in topics_ldamulticore], columns = ['Term'+str(i) for i in range(1, 21)], index=['Topic '+str(t) for t in range(1, ldamulticore.num_topics+1)]).T\n",
    "topics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 most probable words for each topic for LDA  \n",
    "topics_df = pd.DataFrame([[term for term, wt in topic] for topic in topics], columns = ['Term'+str(i) for i in range(1, 21)], index=['Topic '+str(t) for t in range(1, topics.num_topics+1)]).T\n",
    "topics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all the terms for each topic for LDA Mallet\n",
    "#pd.set_option('display.max_colwidth', -1)\n",
    "#topics_df = pd.DataFrame([', '.join([term for term, wt in topic]) for topic in topics], columns = ['Terms per Topic'], index=['Topic'+str(t) for t in range(1, ldamallet.num_topics+1)] )\n",
    "#topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all the terms for each topic for LDA Multicore\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "topics_df_ldam = pd.DataFrame([', '.join([term for term, wt in topic]) for topic in topics_ldamulticore], columns = ['Terms per Topic'], index=['Topic'+str(t) for t in range(1, ldamulticore.num_topics+1)] )\n",
    "topics_df_ldam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all the terms for each topic for LDA \n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "topics_df_lda = pd.DataFrame([', '.join([term for term, wt in topic]) for topic in topics_ldam], columns = ['Terms per Topic'], index=['Topic'+str(t) for t in range(1, ldamodel.num_topics+1)] )\n",
    "topics_df_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualize the LDA Mallet terms as wordclouds\n",
    "from wordcloud import WordCloud # Import wordclouds\n",
    "\n",
    "# Initiate the wordcloud object\n",
    "wc = WordCloud(background_color=\"white\", colormap=\"Dark2\", max_font_size=150, random_state=42)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20, 15]\n",
    "\n",
    "# Create subplots for each topic\n",
    "for i in range(25):\n",
    "\n",
    "    wc.generate(text=topics_df[\"Terms per Topic\"][i])\n",
    "    \n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(topics_df.index[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the LDA Multicore terms as wordclouds\n",
    "from wordcloud import WordCloud # Import wordclouds\n",
    "\n",
    "# Initiate the wordcloud object\n",
    "wc = WordCloud(background_color=\"white\", colormap=\"Dark2\", max_font_size=150, random_state=42)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20, 15]\n",
    "plt.title(\"LDA Multicore Output\")\n",
    "\n",
    "\n",
    "# Create subplots for each topic\n",
    "for i in range(25):\n",
    "    wc.generate(text=topics_df_ldam[\"Terms per Topic\"][i])\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(topics_df_ldam.index[i])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the LDA terms as wordclouds\n",
    "from wordcloud import WordCloud # Import wordclouds\n",
    "\n",
    "# Initiate the wordcloud object\n",
    "wc = WordCloud(background_color=\"white\", colormap=\"Dark2\", max_font_size=150, random_state=42)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20, 15]\n",
    "plt.title(\"LDA Output\")\n",
    "startoffset = 25\n",
    "# Create subplots for each topic\n",
    "for i in range(25):\n",
    "    wc.generate(text=topics_df_lda[\"Terms per Topic\"][i+startoffset])\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(topics_df_lda.index[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the LDA terms as wordclouds\n",
    "from wordcloud import WordCloud # Import wordclouds\n",
    "\n",
    "# Initiate the wordcloud object\n",
    "wc = WordCloud(background_color=\"white\", colormap=\"Dark2\", max_font_size=150, random_state=42)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "plt.title(\"LDA Output\")\n",
    "\n",
    "# Create subplots for each topic\n",
    "\n",
    "wc.generate(text=topics_df_ldam[\"Terms per Topic\"][75])\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.imshow(wc, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim as gensimvis\n",
    "vis_data = gensimvis.prepare(ldagensim, corpus, id2word, sort_topics=False)\n",
    "pyLDAvis.display(vis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim as gensimvis\n",
    "vis_data = gensimvis.prepare(ldamulticore, corpus, id2word, sort_topics=False)\n",
    "pyLDAvis.display(vis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim as gensimvis\n",
    "vis_data = gensimvis.prepare(ldamodel, corpus, id2word, sort_topics=False)\n",
    "pyLDAvis.display(vis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle #picke the result for later use\n",
    "pickle.dump(processed_data, open(\"processed_data_100_QAT.pkl\", \"wb\"))\n",
    "pickle.dump(ldamulticore, open(\"ldamulticore_100_QAT.pkl\", \"wb\"))\n",
    "pickle.dump(ldamodel, open(\"ldamodel_100_QAT.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle #Unpickle the previous results\n",
    "from gensim.models import CoherenceModel\n",
    "corpus = pickle.load(open(\"C:\\\\Users\\\\hamed\\\\Desktop\\\\ECE 143 Project Data Files\\\\corpus_100_QAT.pkl\", \"rb\"))\n",
    "id2word = pickle.load(open(\"C:\\\\Users\\\\hamed\\\\Desktop\\\\ECE 143 Project Data Files\\\\id2word_100_QAT.pkl\", \"rb\"))\n",
    "processed_data = pickle.load(open(\"C:\\\\Users\\\\hamed\\\\Desktop\\\\ECE 143 Project Data Files\\\\processed_data_100_QAT.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim as gensimvis\n",
    "vis_data = gensimvis.prepare(ldamodel, corpus, id2word, sort_topics=False)\n",
    "pyLDAvis.display(vis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis #Import pyLDAvis for interactive visualization\n",
    "pyLDAvis.display(vis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis # Save the interactive \n",
    "pyLDAvis.save_html(vis_data, \"C:\\\\Users\\\\hamed\\\\Desktop\\\\ECE 143 Project Data Files\\\\lda_visulaization_100.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of \"Tags\" distribution\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import collections\n",
    "from collections import OrderedDict\n",
    "file_tags = 'C:\\\\Users\\\\hamed\\\\Desktop\\\\ECE 143 Project Data Files\\\\Tags.csv'\n",
    "Tags_r = pd.read_csv(file_tags, engine ='python',usecols = ['Tag'], encoding = 'iso-8859-1',error_bad_lines=False)\n",
    "tags_count = collections.Counter(Tags)\n",
    "common_tags = OrderedDict(tags_count.most_common(18))\n",
    "del common_tags['python'] # remove non-infomative tags\n",
    "del common_tags['python-2.7']\n",
    "del common_tags['python-3.x']\n",
    "labels, values = zip(*common_tags.items())\n",
    "values = [v/1000 for v in values] # Change the frequency to thousends\n",
    "s = pd.Series(\n",
    "   values, labels\n",
    ")\n",
    "plt.figure(figsize=(80,30))\n",
    "\n",
    "ax = s.plot.bar(x=\"labels\", y=\"values\", rot=0,color=[(174/255,199/255,232/255)])\n",
    "plt.title('Top 15 Most Frequent Tags \\n', fontsize=60,fontfamily='Nunito')\n",
    "plt.xlabel('\\nTags', fontsize=55,fontfamily='Nunito')\n",
    "plt.ylabel('   Frequency \\n (thousands)\\n ', fontsize=55,fontfamily='Nunito')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "from matplotlib import rcParams\n",
    "plt.rcParams.update({'font.size': 40,'font.family':'Nunito'})\n",
    "rects = ax.patches\n",
    "# Make some labels.\n",
    "\n",
    "labels = ['62.8k','26.8k','25.8k','18.9k','16.5k','14k','13.4k','10.7k','10.6k','10.4k','10.2k','9.3k','9.1k','8k','7.5k']\n",
    "\n",
    "# Add labels on top of the bars\n",
    "for rect, label in zip(rects, labels):\n",
    "    height = rect.get_height()\n",
    "    ax.text(rect.get_x() + rect.get_width() / 2, height + 1, label,\n",
    "            ha='center', va='bottom')    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute coherance score for different topic values\n",
    "lda_models, coherence_scores = topic_model_coherence_generator(corpus=corpus, texts=processed_data, dictionary=id2word, start_topic_count=25, end_topic_count=150, step=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim #Import gensim for topic modelling \n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import LdaModel\n",
    "import os\n",
    "format =\".pkl\"\n",
    "\n",
    "def topic_model_coherence_generator(corpus, texts, dictionary, start_topic_count=25, end_topic_count=125, step=25):\n",
    "    \"\"\"Get the coherance score for differnt topic values from 25 and 150\"\"\"\n",
    "  models = []\n",
    "  coherence_scores = []\n",
    "  for topic_nums in tqdm(range(start_topic_count, end_topic_count+1, step)):\n",
    "    ldamodel = LdaModel(corpus=corpus, num_topics=topic_nums, id2word=id2word, eval_every=None, passes=20,per_word_topics=True)\n",
    "    dir_name=\"C:\\\\Users\\\\hamed\\\\OneDrive\\\\Desktop\\\\ECE 143 Project Data Files\\\\\"\n",
    "    save_dir=os.path.join(dir_name, \"ldamodel_\"+ str(topic_nums) +\"_QAT_3_7\" + format)\n",
    "    pickle.dump(ldamodel, open(save_dir, \"wb\"))\n",
    "    \n",
    "    cv_coherence_model_lda = gensim.models.CoherenceModel (model=ldamodel, corpus=corpus, texts=texts,\n",
    "                                                                     dictionary=dictionary, coherence='c_v')\n",
    "      \n",
    "    coherence_score = cv_coherence_model_lda.get_coherence()\n",
    "    coherence_scores.append(coherence_score)\n",
    "    models.append(ldamodel)\n",
    "  return models, coherence_scores  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
